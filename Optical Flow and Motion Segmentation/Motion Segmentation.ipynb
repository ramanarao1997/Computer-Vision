{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import common_23 as common # This file works in Python 3. video works in python2\n",
    "import video_23 as video # This file works in Python 3. video works for python2\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import time \n",
    "import sys\n",
    "from contextlib import contextmanager\n",
    "import itertools as it\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert file folder to video if you have frame sequences instead of a video\n",
    "\n",
    "def fr2vid(inputpath, outputfile):\n",
    "    pathIn= inputpath\n",
    "    pathOut = outputfile\n",
    "    fps = 32\n",
    "    frame_array = []\n",
    "    files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
    "    #for sorting the file names properly\n",
    "    files.sort(key = lambda x: x[5:-4])\n",
    "    files.sort()\n",
    "    frame_array = []\n",
    "    files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
    "    #for sorting the file names properly\n",
    "    files.sort(key = lambda x: x[5:-4])\n",
    "    for i in range(len(files)):\n",
    "        filename=pathIn + files[i]\n",
    "        #reading each files\n",
    "        img = cv2.imread(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "    \n",
    "        #inserting the frames into an image array\n",
    "        frame_array.append(img)\n",
    "    out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "    for i in range(len(frame_array)):\n",
    "        # writing to a image array\n",
    "        out.write(frame_array[i])\n",
    "    out.release()\n",
    "\n",
    "    \n",
    "#fr2vid('./house/','house.avi') #convert sequence to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homework 3 -- Motion Segmentation helper code\n",
    "\n",
    "def motion_seg(inputfile):\n",
    "    cap = video.create_capture(inputfile)\n",
    "    ret, first = cap.read()\n",
    "\n",
    "    # For background subtraction, Save the first image as reference\n",
    "    first_gray = cv2.cvtColor(first, cv2.COLOR_BGR2GRAY)\n",
    "    first_gray = cv2.GaussianBlur(first_gray, (21, 21), 0)\n",
    "    start = time.time()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "    \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "        # In each iteration, calculate absolute difference between current frame and reference frame\n",
    "        difference = cv2.absdiff(gray, first_gray)\n",
    "\n",
    "        # Apply thresholding to eliminate noise\n",
    "        thresh = cv2.threshold(difference, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "        thresh = cv2.dilate(thresh, None, iterations=5)\n",
    "        \n",
    "        cv2.imshow(\"thresh\", thresh)\n",
    "        key = cv2.waitKey(5) & 0xFF \n",
    "    \n",
    "        # if the `q` key is pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7204179763793945\n"
     ]
    }
   ],
   "source": [
    "motion_seg('videos/rock.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem II - Motion Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the video sequences on which we test the below algorithms\n",
    "video_sequences = ['rock.avi','beach.avi','jug.avi','lights.avi','railway.avi','trees.avi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-adaptive frame differencing algorithm\n",
    "\n",
    "def non_adaptive_frame_differencing(inputfile, threshold):\n",
    "    cap = video.create_capture(inputfile)\n",
    "    ret, first = cap.read()\n",
    "\n",
    "    # For background subtraction, Save the first image as reference\n",
    "    first_gray = cv2.cvtColor(first, cv2.COLOR_BGR2GRAY)\n",
    "    first_gray = cv2.GaussianBlur(first_gray, (21, 21), 0)\n",
    "    start = time.time()\n",
    "    backgroundFrame = first_gray\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "    \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "        currentFrame = gray\n",
    "        \n",
    "        # In each iteration, calculate absolute difference between current frame and reference frame\n",
    "        foreground = cv2.absdiff(backgroundFrame, currentFrame)\n",
    "\n",
    "        # Apply thresholding to eliminate noise\n",
    "        foreground = cv2.threshold(foreground, threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "        foreground = cv2.dilate(foreground, None, iterations = 5)\n",
    "        \n",
    "        cv2.imshow(\"Non-adaptive frame differencing on {0} with threshold = {1}\".format(inputfile, threshold), foreground)\n",
    "        backgroundFrame = currentFrame\n",
    "        key = cv2.waitKey(5) & 0xFF \n",
    "    \n",
    "        # if the `q` key is pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Time taken for threshold {0}: '.format(threshold) + str(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For the rock.avi video sequence:\n",
      "Time taken for threshold 0: 2.6640098094940186\n",
      "Time taken for threshold 5: 2.5661139488220215\n",
      "Time taken for threshold 10: 2.778369903564453\n",
      "Time taken for threshold 15: 3.0497889518737793\n",
      "Time taken for threshold 20: 3.1344399452209473\n",
      "Time taken for threshold 25: 2.9832229614257812\n",
      "Time taken for threshold 30: 3.0762503147125244\n",
      "\n",
      "For the beach.avi video sequence:\n",
      "Time taken for threshold 0: 1.6241412162780762\n",
      "Time taken for threshold 5: 1.7264900207519531\n",
      "Time taken for threshold 10: 1.8678529262542725\n",
      "Time taken for threshold 15: 1.4176647663116455\n",
      "Time taken for threshold 20: 1.7039477825164795\n",
      "Time taken for threshold 25: 1.7879207134246826\n",
      "Time taken for threshold 30: 1.7081005573272705\n",
      "\n",
      "For the jug.avi video sequence:\n",
      "Time taken for threshold 0: 1.7637195587158203\n",
      "Time taken for threshold 5: 1.7560093402862549\n",
      "Time taken for threshold 10: 1.461838960647583\n",
      "Time taken for threshold 15: 1.776118516921997\n",
      "Time taken for threshold 20: 1.4714829921722412\n",
      "Time taken for threshold 25: 1.3932607173919678\n",
      "Time taken for threshold 30: 1.5119996070861816\n",
      "\n",
      "For the lights.avi video sequence:\n",
      "Time taken for threshold 0: 0.8383650779724121\n",
      "Time taken for threshold 5: 0.8799989223480225\n",
      "Time taken for threshold 10: 0.8879685401916504\n",
      "Time taken for threshold 15: 0.9541349411010742\n",
      "Time taken for threshold 20: 0.8120014667510986\n",
      "Time taken for threshold 25: 0.8439977169036865\n",
      "Time taken for threshold 30: 0.8440001010894775\n",
      "\n",
      "For the railway.avi video sequence:\n",
      "Time taken for threshold 0: 1.771998643875122\n",
      "Time taken for threshold 5: 1.632000207901001\n",
      "Time taken for threshold 10: 1.6239979267120361\n",
      "Time taken for threshold 15: 1.644000768661499\n",
      "Time taken for threshold 20: 1.6359977722167969\n",
      "Time taken for threshold 25: 1.4119985103607178\n",
      "Time taken for threshold 30: 1.3568572998046875\n",
      "\n",
      "For the trees.avi video sequence:\n",
      "Time taken for threshold 0: 1.0120000839233398\n",
      "Time taken for threshold 5: 1.107999324798584\n",
      "Time taken for threshold 10: 0.9919998645782471\n",
      "Time taken for threshold 15: 0.9919993877410889\n",
      "Time taken for threshold 20: 1.242633581161499\n",
      "Time taken for threshold 25: 1.2039997577667236\n",
      "Time taken for threshold 30: 1.1399993896484375\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0, 5, 10, 15, 20, 25, 30]\n",
    "\n",
    "for seq in video_sequences:\n",
    "    print('\\nFor the {} video sequence:'.format(seq))\n",
    "    for threshold in thresholds:\n",
    "        non_adaptive_frame_differencing('videos/' + seq, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report for Non-adaptive frame differencing\n",
    "\n",
    "Frame differencing techniques try to improve the naive approach of background subtraction by replacing the background model with the previous image frame.\n",
    "\n",
    "Non-adaptive frame differencing simply treats the previous image frame as the new background and hence it does not leave behind ghosts of the objects that start and also does not detect the objects that halt. It also adapts to changes in lightning and motion of the camera. But, frame differencing only detects the leading and trailing edges of a uniformly colored moving object which makes it is very hard to detect an object moving towards/away from the camera.\n",
    "\n",
    "#### Effect of threshold:\n",
    "By running the above algorithm on different sequences for the following thresholds [0, 5, 10, 15, 20, 25, 30], we observe that:\n",
    "\n",
    "As the threshold increases, the number of objects which have motion in the output decreases. This is because if we increase the threshold value only objects with significant motion get detected. Low threshold (say 0) treats even small movements as significant while a high threshold (say 30) only filters some objects. We could say that the threshold value of 10 gives good results on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive frame differencing algorithm\n",
    "def adaptive_frame_differencing(inputfile, alpha, threshold):\n",
    "    cap = video.create_capture(inputfile)\n",
    "    ret, first = cap.read()\n",
    "\n",
    "    # For background subtraction, Save the first image as reference\n",
    "    first_gray = cv2.cvtColor(first, cv2.COLOR_BGR2GRAY)\n",
    "    first_gray = cv2.GaussianBlur(first_gray, (21, 21), 0)\n",
    "    start = time.time()\n",
    "    backgroundFrame = first_gray\n",
    "    i = 1\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "    \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "        currentFrame = gray\n",
    "        \n",
    "        # In each iteration, calculate absolute difference between current frame and reference frame\n",
    "        foreground = cv2.absdiff(backgroundFrame, currentFrame)\n",
    "\n",
    "        # Apply thresholding to eliminate noise\n",
    "        foreground = cv2.threshold(foreground, threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "        foreground = cv2.dilate(foreground, None, iterations=5)\n",
    "        \n",
    "        cv2.imshow(\"Adaptive frame differencing on {0} with alpha = {1} and  threshold = {2}\".format(inputfile, alpha, threshold), foreground)\n",
    "        \n",
    "        backgroundFrame = cv2.addWeighted(currentFrame, alpha, backgroundFrame, 1.0 - alpha, 0)\n",
    "        key = cv2.waitKey(5) & 0xFF \n",
    "    \n",
    "        # if the `q` key is pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print('\\tTime taken for threshold {0}: '.format(threshold) + str(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For the rock.avi video sequence:\n",
      "For alpha = 1\n",
      "\tTime taken for threshold 10: 3.102043867111206\n",
      "\tTime taken for threshold 20: 2.7040255069732666\n",
      "For alpha = 0.75\n",
      "\tTime taken for threshold 10: 2.841611385345459\n",
      "\tTime taken for threshold 20: 2.34305477142334\n",
      "For alpha = 0.5\n",
      "\tTime taken for threshold 10: 2.45999813079834\n",
      "\tTime taken for threshold 20: 2.3201980590820312\n",
      "For alpha = 0.25\n",
      "\tTime taken for threshold 10: 2.805173397064209\n",
      "\tTime taken for threshold 20: 2.3097221851348877\n",
      "For alpha = 0\n",
      "\tTime taken for threshold 10: 2.534735679626465\n",
      "\tTime taken for threshold 20: 2.3295140266418457\n",
      "\n",
      "For the beach.avi video sequence:\n",
      "For alpha = 1\n",
      "\tTime taken for threshold 10: 1.308960199356079\n",
      "\tTime taken for threshold 20: 1.7035503387451172\n",
      "For alpha = 0.75\n",
      "\tTime taken for threshold 10: 1.7836167812347412\n",
      "\tTime taken for threshold 20: 1.635488748550415\n",
      "For alpha = 0.5\n",
      "\tTime taken for threshold 10: 1.268000602722168\n",
      "\tTime taken for threshold 20: 1.5056769847869873\n",
      "For alpha = 0.25\n",
      "\tTime taken for threshold 10: 1.252582311630249\n",
      "\tTime taken for threshold 20: 1.295999526977539\n",
      "For alpha = 0\n",
      "\tTime taken for threshold 10: 1.260000467300415\n",
      "\tTime taken for threshold 20: 1.26399827003479\n",
      "\n",
      "For the jug.avi video sequence:\n",
      "For alpha = 1\n",
      "\tTime taken for threshold 10: 1.2560012340545654\n",
      "\tTime taken for threshold 20: 1.4226129055023193\n",
      "For alpha = 0.75\n",
      "\tTime taken for threshold 10: 1.2839581966400146\n",
      "\tTime taken for threshold 20: 1.3600001335144043\n",
      "For alpha = 0.5\n",
      "\tTime taken for threshold 10: 1.568000316619873\n",
      "\tTime taken for threshold 20: 1.5292229652404785\n",
      "For alpha = 0.25\n",
      "\tTime taken for threshold 10: 1.4720635414123535\n",
      "\tTime taken for threshold 20: 1.360976219177246\n",
      "For alpha = 0\n",
      "\tTime taken for threshold 10: 1.3479485511779785\n",
      "\tTime taken for threshold 20: 1.495995283126831\n",
      "\n",
      "For the lights.avi video sequence:\n",
      "For alpha = 1\n",
      "\tTime taken for threshold 10: 1.2751104831695557\n",
      "\tTime taken for threshold 20: 0.8814432621002197\n",
      "For alpha = 0.75\n",
      "\tTime taken for threshold 10: 0.795996904373169\n",
      "\tTime taken for threshold 20: 0.8919951915740967\n",
      "For alpha = 0.5\n",
      "\tTime taken for threshold 10: 0.8279976844787598\n",
      "\tTime taken for threshold 20: 0.8079981803894043\n",
      "For alpha = 0.25\n",
      "\tTime taken for threshold 10: 1.3117868900299072\n",
      "\tTime taken for threshold 20: 0.8119993209838867\n",
      "For alpha = 0\n",
      "\tTime taken for threshold 10: 0.9405074119567871\n",
      "\tTime taken for threshold 20: 0.8245275020599365\n",
      "\n",
      "For the railway.avi video sequence:\n",
      "For alpha = 1\n",
      "\tTime taken for threshold 10: 1.5831022262573242\n",
      "\tTime taken for threshold 20: 1.4170246124267578\n",
      "For alpha = 0.75\n",
      "\tTime taken for threshold 10: 1.508000135421753\n",
      "\tTime taken for threshold 20: 1.740464210510254\n",
      "For alpha = 0.5\n",
      "\tTime taken for threshold 10: 1.6079578399658203\n",
      "\tTime taken for threshold 20: 1.4257125854492188\n",
      "For alpha = 0.25\n",
      "\tTime taken for threshold 10: 1.3440024852752686\n",
      "\tTime taken for threshold 20: 1.6760003566741943\n",
      "For alpha = 0\n",
      "\tTime taken for threshold 10: 1.359999656677246\n",
      "\tTime taken for threshold 20: 1.3199958801269531\n",
      "\n",
      "For the trees.avi video sequence:\n",
      "For alpha = 1\n",
      "\tTime taken for threshold 10: 1.124023675918579\n",
      "\tTime taken for threshold 20: 1.0879907608032227\n",
      "For alpha = 0.75\n",
      "\tTime taken for threshold 10: 0.9818124771118164\n",
      "\tTime taken for threshold 20: 0.9448850154876709\n",
      "For alpha = 0.5\n",
      "\tTime taken for threshold 10: 0.9440827369689941\n",
      "\tTime taken for threshold 20: 0.9760012626647949\n",
      "For alpha = 0.25\n",
      "\tTime taken for threshold 10: 1.5320003032684326\n",
      "\tTime taken for threshold 20: 1.5225365161895752\n",
      "For alpha = 0\n",
      "\tTime taken for threshold 10: 1.343646764755249\n",
      "\tTime taken for threshold 20: 0.9523017406463623\n"
     ]
    }
   ],
   "source": [
    "alpha_values = [1, 0.75, 0.5, 0.25, 0]\n",
    "thresholds = [10, 20]\n",
    "\n",
    "for seq in video_sequences:\n",
    "    print('\\nFor the {} video sequence:'.format(seq))\n",
    "    for alpha in alpha_values:\n",
    "        print('For alpha = {}'.format(alpha))\n",
    "        for threshold in thresholds:\n",
    "            adaptive_frame_differencing('videos/'+ seq, alpha,threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report for Adaptive frame differencing\n",
    "\n",
    "Frame differencing techniques try to improve the naive approach of background subtraction by replacing the background model with the previous image frame.\n",
    "\n",
    "\n",
    "Adaptive frame differencing blends the current image frame into background model using a paramter alpha. If alpha = 0, we get simple bakground subtraction and if alpha = 1 we get non-adaptive frame differencing. As this technique uses alpha as the blending parameter, it gradually eliminates the ghosts of the objects that start and also gradually gets rid of the objects that halt. \n",
    "\n",
    "By running the above algorithm on different sequences for the following alpha values [1, 0.75, 0.5, 0.25, 0] and the following thresholds [10, 20, 30], we observe that:\n",
    "\n",
    "#### Effect of alpha:\n",
    "As alpha decreases, the time taken for ghosts to blend into the background increases. Also, alpha = 1 produces the same result as non-adaptive frame differencing algorithm with the same threshold. Further, aplha = 0 leaves behind ghosts as it is equivalent to simple background subtraction. Overall, the alpha value of 0.5 seems to produce good results.\n",
    "\n",
    "#### Effect of threshold:\n",
    "As the threshold increases, the number of objects which have motion in the output decreases. This is because if we increase the threshold value only objects with significant motion get detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistent frame differencing algorithm\n",
    "\n",
    "def persistent_frame_differencing(inputfile, gamma, threshold):\n",
    "    cap = video.create_capture(inputfile)\n",
    "    ret, first = cap.read()\n",
    "\n",
    "    # For background subtraction, Save the first image as reference\n",
    "    first_gray = cv2.cvtColor(first, cv2.COLOR_BGR2GRAY)\n",
    "    first_gray = cv2.GaussianBlur(first_gray, (21, 21), 0)\n",
    "    \n",
    "    backgroundFrame = first_gray\n",
    "    \n",
    "    h, w = first_gray.shape[:2]\n",
    "    motion_history = np.zeros((h, w),np.float32)\n",
    "    start = time.time()\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "    \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "        currentFrame = gray\n",
    "        \n",
    "        # In each iteration, calculate absolute difference between current frame and reference frame\n",
    "        foreground = cv2.absdiff(backgroundFrame, currentFrame)\n",
    "\n",
    "        # Apply thresholding to eliminate noise\n",
    "        foreground = cv2.threshold(foreground, threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "        foreground = cv2.dilate(foreground, None, iterations = 5)\n",
    "        \n",
    "        motion_history = motion_history - gamma\n",
    "        motion_history[motion_history < 0] = 0\n",
    "        tmp = motion_history\n",
    "        \n",
    "        foreground = 255 * foreground\n",
    "        \n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                if foreground[i, j] > tmp[i, j]:\n",
    "                    motion_history[i,j] = foreground[i, j]\n",
    "                else:\n",
    "                    motion_history[i,j] = tmp[i, j] \n",
    "        \n",
    "        cv2.imshow(\"Persistent frame differencing on {0} with gamma = {1} and threshold = {2}\".format(inputfile, gamma, threshold) ,motion_history)\n",
    "        backgroundFrame = currentFrame\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF \n",
    "    \n",
    "        # if the `q` key is pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Time taken for threshold {0}: '.format(threshold) + str(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for threshold 10: 11.896270036697388\n"
     ]
    }
   ],
   "source": [
    "persistent_frame_differencing('videos/rock.avi', 0.25, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment to run for all sequences and different values of gamma and threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma_values = [0, 0.125, 0.25, 0.375, 0.5]\n",
    "# thresholds = [10, 20]\n",
    "\n",
    "# for seq in video_sequences:\n",
    "#     print('\\nFor the {} video sequence:'.format(seq))\n",
    "#     for threshold in thresholds:\n",
    "#         persistent_frame_differencing('videos/' + seq, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report for Persistant frame differencing\n",
    "\n",
    "In this technique we use motion history of the image and mark a pixel with the last time it was detected foreground. This gives us a sense of motion with some kind of fading trail of the objects that move.\n",
    "\n",
    "Since the background image is updated using the current image frame the ghosts fade away. It also adapts to changes in motion of the camera and illumination.\n",
    "\n",
    "#### Effect of Gamma:\n",
    "By running the algorithm on the following gamma values [0, 0.125, 0.25, 0.375, 0.5] we see that as the value of gamma decreases, the motion history of the image is clearly seen i.e the objects have longer trails. But, gamma value of 0 will retain the trail of the object as a ghost. As gamma increases the we no longer see the motion history. Of the given values gamma value of 0.25 seems optimal. \n",
    "\n",
    "#### Effect of threshold:\n",
    "By running the above algorithm on different sequences for the following thresholds [10, 20], we observe that:\n",
    "\n",
    "As the threshold increases, the number of objects which have motion in the output decreases. This is because if we increase the threshold value only objects with significant motion get detected. Low threshold (say 10) treats even small movements as significant while a high threshold (say 20) only filters bodies with large motion. We could say that the threshold value of 10 gives good results on average."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
